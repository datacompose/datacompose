# Getting Started

Welcome to Datacompose! This section will help you get up and running quickly.

## Overview

Datacompose is a code generation framework that creates reusable data transformation primitives for PySpark. Unlike traditional libraries, Datacompose generates code that becomes part of your project - you own it, can modify it, and have zero runtime dependencies.

## Quick Navigation

<div class="grid cards" markdown>

-   :material-download:{ .lg .middle } **[Installation](installation.md)**

    ---

    Install Datacompose and set up your environment

-   :material-rocket-launch:{ .lg .middle } **[Quick Start](quickstart.md)**

    ---

    Create your first data transformation pipeline in minutes

</div>

## What You'll Learn

By the end of this section, you'll know how to:

- âœ… Install Datacompose and its dependencies
- âœ… Initialize a new Datacompose project
- âœ… Generate transformation primitives for common data cleaning tasks
- âœ… Use the generated code in your PySpark applications
- âœ… Create custom pipelines by composing primitives

## Prerequisites

Before you begin, make sure you have:

- **Python 3.8+** installed on your system
- **Java 8 or 11** for PySpark (check with `java -version`)
- Basic familiarity with PySpark DataFrames
- A terminal or command prompt

## Choose Your Path

### I want to start quickly
â†’ Jump to the [Quick Start](quickstart.md) guide

### I want to understand the installation process
â†’ Read the [Installation](installation.md) guide first

### I want to see what Datacompose can do
â†’ Check out the [Examples](../examples/index.md) section

## Need Help?

- ğŸ“– Read the [User Guide](../user-guide/index.md) for detailed explanations
- ğŸ” Browse the [API Reference](../api/index.md) for all available functions
- ğŸ’¬ Ask questions on [GitHub Discussions](https://github.com/datacompose/datacompose/discussions)
- ğŸ› Report issues on [GitHub Issues](https://github.com/datacompose/datacompose/issues)