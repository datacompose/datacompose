# Getting Started

Welcome to Datacompose! This section will help you get up and running quickly.

## Overview

Datacompose is a code generation framework that creates reusable data transformation primitives for PySpark. Unlike traditional libraries, Datacompose generates code that becomes part of your project - you own it, can modify it, and have zero runtime dependencies.

## Quick Navigation

<div class="grid cards" markdown>

-   :material-download:{ .lg .middle } **[Installation](installation.md)**

    ---

    Install Datacompose and set up your environment

-   :material-rocket-launch:{ .lg .middle } **[Quick Start](quickstart.md)**

    ---

    Create your first data transformation pipeline in minutes

</div>

## What You'll Learn

By the end of this section, you'll know how to:

- ✅ Install Datacompose and its dependencies
- ✅ Initialize a new Datacompose project
- ✅ Generate transformation primitives for common data cleaning tasks
- ✅ Use the generated code in your PySpark applications
- ✅ Create custom pipelines by composing primitives

## Prerequisites

Before you begin, make sure you have:

- **Python 3.8+** installed on your system
- **Java 8 or 11** for PySpark (check with `java -version`)
- Basic familiarity with PySpark DataFrames
- A terminal or command prompt

## Choose Your Path

### I want to start quickly
→ Jump to the [Quick Start](quickstart.md) guide

### I want to understand the installation process
→ Read the [Installation](installation.md) guide first

### I want to see what Datacompose can do
→ Check out the [Examples](../examples/index.md) section

## Need Help?

- 📖 Read the [User Guide](../user-guide/index.md) for detailed explanations
- 🔍 Browse the [API Reference](../api/index.md) for all available functions
- 💬 Ask questions on [GitHub Discussions](https://github.com/datacompose/datacompose/discussions)
- 🐛 Report issues on [GitHub Issues](https://github.com/datacompose/datacompose/issues)